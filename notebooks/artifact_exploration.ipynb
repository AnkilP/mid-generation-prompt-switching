{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD3 Prompt Switching Artifact Exploration\n",
    "\n",
    "This notebook provides interactive tools for exploring artifacts in SD3 during mid-generation prompt switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from IPython.display import display, Image as IPImage\n",
    "import ipywidgets as widgets\n",
    "from src.analysis.artifact_detector import ArtifactDetector\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available experiments\n",
    "artifact_dirs = sorted(Path('../data/artifacts').glob('*'))\n",
    "print(f\"Found {len(artifact_dirs)} experiments:\")\n",
    "for i, dir in enumerate(artifact_dirs[-10:]):  # Show last 10\n",
    "    print(f\"{i}: {dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific experiment\n",
    "exp_idx = -1  # Use most recent\n",
    "artifact_dir = artifact_dirs[exp_idx]\n",
    "\n",
    "# Initialize detector\n",
    "detector = ArtifactDetector(str(artifact_dir))\n",
    "\n",
    "# Show metadata\n",
    "print(\"Experiment metadata:\")\n",
    "for k, v in detector.metadata.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Display output image\n",
    "display(IPImage(str(artifact_dir / 'output.png'), width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interactive Latent Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_evolution(detector, channel=0):\n",
    "    \"\"\"Visualize how a specific channel evolves over time.\"\"\"\n",
    "    steps = []\n",
    "    latents_vis = []\n",
    "    \n",
    "    for key in sorted(detector.latents.keys()):\n",
    "        if \"latents_step_\" in key:\n",
    "            step = int(key.split(\"_\")[-1])\n",
    "            latent = detector.latents[key]\n",
    "            steps.append(step)\n",
    "            latents_vis.append(latent[0, channel].numpy())\n",
    "    \n",
    "    # Create grid visualization\n",
    "    n_steps = len(steps)\n",
    "    cols = min(6, n_steps)\n",
    "    rows = (n_steps + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten() if n_steps > 1 else [axes]\n",
    "    \n",
    "    vmin = min(l.min() for l in latents_vis)\n",
    "    vmax = max(l.max() for l in latents_vis)\n",
    "    \n",
    "    for idx, (step, latent) in enumerate(zip(steps, latents_vis)):\n",
    "        if idx < len(axes):\n",
    "            im = axes[idx].imshow(latent, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "            axes[idx].set_title(f'Step {step}')\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "            # Mark switch step\n",
    "            if step == detector.switch_step:\n",
    "                axes[idx].set_title(f'Step {step} (SWITCH)', color='red')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(steps), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Latent Channel {channel} Evolution', fontsize=16)\n",
    "    plt.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "channel_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=15, step=1,\n",
    "    description='Channel:'\n",
    ")\n",
    "widgets.interactive(visualize_latent_evolution, detector=widgets.fixed(detector), channel=channel_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artifact Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run artifact detection\n",
    "discontinuities = detector.detect_discontinuities(threshold_multiplier=2.0)\n",
    "\n",
    "print(\"Detected discontinuities:\")\n",
    "for artifact_type, detections in discontinuities.items():\n",
    "    if detections:\n",
    "        print(f\"\\n{artifact_type}:\")\n",
    "        for step, value in detections:\n",
    "            distance = step - detector.switch_step\n",
    "            print(f\"  Step {step} (switch{distance:+d}): {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize artifacts\n",
    "plots = detector.visualize_artifacts()\n",
    "print(f\"Generated {len(plots)} visualizations\")\n",
    "\n",
    "# Display them\n",
    "for name, path in plots.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    display(IPImage(str(path), width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attention Map Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if attention maps were captured\n",
    "attention_maps = torch.load(artifact_dir / 'attention_maps.pt') if (artifact_dir / 'attention_maps.pt').exists() else {}\n",
    "\n",
    "if attention_maps:\n",
    "    print(f\"Found {len(attention_maps)} attention maps\")\n",
    "    \n",
    "    # Analyze attention pattern changes\n",
    "    def plot_attention_entropy():\n",
    "        entropies = {}\n",
    "        \n",
    "        for key, attn in attention_maps.items():\n",
    "            if \"_step_\" in key:\n",
    "                step = int(key.split(\"_\")[-1])\n",
    "                # Compute entropy of attention distribution\n",
    "                attn_probs = torch.softmax(attn.flatten(), dim=0)\n",
    "                entropy = -torch.sum(attn_probs * torch.log(attn_probs + 1e-10))\n",
    "                entropies[step] = float(entropy)\n",
    "        \n",
    "        if entropies:\n",
    "            steps = sorted(entropies.keys())\n",
    "            entropy_values = [entropies[s] for s in steps]\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(steps, entropy_values, 'b-', marker='o')\n",
    "            plt.axvline(x=detector.switch_step, color='r', linestyle='--', label='Prompt Switch')\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('Attention Entropy')\n",
    "            plt.title('Attention Distribution Entropy Over Time')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.show()\n",
    "    \n",
    "    plot_attention_entropy()\n",
    "else:\n",
    "    print(\"No attention maps found in this experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Experiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple experiments\n",
    "from src.analysis.artifact_detector import compare_experiments\n",
    "\n",
    "# Select recent experiments to compare\n",
    "compare_dirs = [str(d) for d in artifact_dirs[-5:]]\n",
    "comparisons = compare_experiments(compare_dirs)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Discontinuity counts\n",
    "exp_names = [Path(d).name[-6:] for d in compare_dirs]\n",
    "counts = [comparisons['discontinuity_counts'].get(d, 0) for d in compare_dirs]\n",
    "\n",
    "ax1.bar(exp_names, counts, alpha=0.7)\n",
    "ax1.set_xlabel('Experiment')\n",
    "ax1.set_ylabel('Total Discontinuities')\n",
    "ax1.set_title('Artifact Count Comparison')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average discontinuity magnitude\n",
    "avg_disc = [comparisons['avg_switch_discontinuity'].get(d, 0) for d in compare_dirs]\n",
    "\n",
    "ax2.bar(exp_names, avg_disc, alpha=0.7, color='orange')\n",
    "ax2.set_xlabel('Experiment')\n",
    "ax2.set_ylabel('Avg Discontinuity')\n",
    "ax2.set_title('Average Discontinuity Magnitude')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pattern Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for patterns in when artifacts occur\n",
    "def analyze_temporal_patterns(detector):\n",
    "    \"\"\"Analyze when artifacts tend to occur relative to switch.\"\"\"\n",
    "    discontinuities = detector.detect_discontinuities()\n",
    "    \n",
    "    # Collect all artifact timings relative to switch\n",
    "    relative_timings = []\n",
    "    \n",
    "    for artifact_type, detections in discontinuities.items():\n",
    "        for step, value in detections:\n",
    "            relative_timing = step - detector.switch_step\n",
    "            relative_timings.append(relative_timing)\n",
    "    \n",
    "    if relative_timings:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(relative_timings, bins=20, alpha=0.7, edgecolor='black')\n",
    "        plt.axvline(x=0, color='r', linestyle='--', label='Switch Point')\n",
    "        plt.xlabel('Steps Relative to Switch')\n",
    "        plt.ylabel('Artifact Count')\n",
    "        plt.title('Temporal Distribution of Artifacts')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"Mean timing: {np.mean(relative_timings):.2f} steps from switch\")\n",
    "        print(f\"Std dev: {np.std(relative_timings):.2f} steps\")\n",
    "        print(f\"Most artifacts within {np.percentile(np.abs(relative_timings), 90):.0f} steps of switch\")\n",
    "\n",
    "analyze_temporal_patterns(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "report = detector.generate_report()\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "report_path = artifact_dir / \"analysis_report.md\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report)\n",
    "print(f\"\\nReport saved to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}